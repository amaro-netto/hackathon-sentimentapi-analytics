{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "r5s0ubSPnitj",
    "ExecuteTime": {
     "end_time": "2026-01-04T02:21:33.919530Z",
     "start_time": "2026-01-04T02:20:51.607988700Z"
    }
   },
   "source": [
    "# No Notebook/Colab, instale a biblioteca primeiro\n",
    "# !pip install datasets pandas pyarrow\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Carregando datasets da Amazon (isso pode levar um momento)...\")\n",
    "\n",
    "# 1. Carrega o subconjunto de Português (pt) e Espanhol (es)\n",
    "#ds_pt = load_dataset(\"mteb/amazon_reviews_multi\", \"pt\", split=\"train\")\n",
    "ds_pt = load_dataset(\"ruanchaves/b2w-reviews01\", split=\"train\")\n",
    "ds_es = load_dataset(\"mteb/amazon_reviews_multi\", \"es\", split=\"train\")\n",
    "\n",
    "# 2. Converte para Pandas DataFrame\n",
    "df_pt = ds_pt.to_pandas()\n",
    "df = ds_es.to_pandas()\n",
    "\n",
    "# 3. Unifica e seleciona as colunas necessárias\n",
    "#df = pd.concat([df_pt, df_es], ignore_index=True)\n",
    "#df = df[['review_body', 'stars', 'language']]\n",
    "\n",
    "print(df_pt.head())\n",
    "print(df.tail())\n",
    "\n",
    "print(f\"Sucesso! Dataset unificado com {len(df)} e {len(df_pt)} registros.\")\n",
    "#print(df['language'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando datasets da Amazon (isso pode levar um momento)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 2.99kB [00:00, ?B/s]\n",
      "Downloading readme: 3.64kB [00:00, ?B/s]\n",
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]\u001B[A\n",
      "Downloading data:   1%|          | 115k/20.5M [00:00<00:17, 1.14MB/s]\u001B[A\n",
      "Downloading data:   4%|▎         | 761k/20.5M [00:00<00:04, 4.18MB/s]\u001B[A\n",
      "Downloading data:   8%|▊         | 1.66M/20.5M [00:00<00:02, 6.29MB/s]\u001B[A\n",
      "Downloading data:  11%|█         | 2.31M/20.5M [00:00<00:02, 6.34MB/s]\u001B[A\n",
      "Downloading data:  15%|█▍        | 2.98M/20.5M [00:00<00:02, 6.41MB/s]\u001B[A\n",
      "Downloading data:  18%|█▊        | 3.64M/20.5M [00:00<00:02, 6.38MB/s]\u001B[A\n",
      "Downloading data:  21%|██        | 4.27M/20.5M [00:00<00:02, 6.25MB/s]\u001B[A\n",
      "Downloading data:  24%|██▍       | 4.90M/20.5M [00:00<00:02, 5.95MB/s]\u001B[A\n",
      "Downloading data:  28%|██▊       | 5.74M/20.5M [00:00<00:02, 6.26MB/s]\u001B[A\n",
      "Downloading data:  32%|███▏      | 6.51M/20.5M [00:01<00:02, 6.55MB/s]\u001B[A\n",
      "Downloading data:  35%|███▌      | 7.22M/20.5M [00:01<00:01, 6.66MB/s]\u001B[A\n",
      "Downloading data:  39%|███▉      | 8.03M/20.5M [00:01<00:01, 6.97MB/s]\u001B[A\n",
      "Downloading data:  44%|████▎     | 8.94M/20.5M [00:01<00:01, 7.51MB/s]\u001B[A\n",
      "Downloading data:  47%|████▋     | 9.69M/20.5M [00:01<00:01, 7.48MB/s]\u001B[A\n",
      "Downloading data:  51%|█████     | 10.4M/20.5M [00:01<00:01, 7.03MB/s]\u001B[A\n",
      "Downloading data:  55%|█████▌    | 11.3M/20.5M [00:01<00:01, 7.44MB/s]\u001B[A\n",
      "Downloading data:  59%|█████▊    | 12.0M/20.5M [00:01<00:01, 6.70MB/s]\u001B[A\n",
      "Downloading data:  62%|██████▏   | 12.8M/20.5M [00:01<00:01, 6.99MB/s]\u001B[A\n",
      "Downloading data:  67%|██████▋   | 13.7M/20.5M [00:02<00:00, 7.36MB/s]\u001B[A\n",
      "Downloading data:  71%|███████   | 14.5M/20.5M [00:02<00:01, 4.55MB/s]\u001B[A\n",
      "Downloading data:  79%|███████▊  | 16.2M/20.5M [00:02<00:00, 6.69MB/s]\u001B[A\n",
      "Downloading data:  83%|████████▎ | 17.0M/20.5M [00:02<00:00, 7.06MB/s]\u001B[A\n",
      "Downloading data:  87%|████████▋ | 17.9M/20.5M [00:02<00:00, 7.22MB/s]\u001B[A\n",
      "Downloading data:  92%|█████████▏| 18.8M/20.5M [00:02<00:00, 7.70MB/s]\u001B[A\n",
      "Downloading data:  96%|█████████▌| 19.7M/20.5M [00:02<00:00, 7.78MB/s]\u001B[A\n",
      "Downloading data: 100%|█████████▉| 20.5M/20.5M [00:03<00:00, 7.47MB/s]\u001B[A\n",
      "Downloading data: 21.3MB [00:03, 7.65MB/s]                            \u001B[A\n",
      "Downloading data: 22.1MB [00:03, 7.04MB/s]\u001B[A\n",
      "Downloading data: 22.9MB [00:03, 5.39MB/s]\u001B[A\n",
      "Downloading data: 23.5MB [00:03, 5.22MB/s]\u001B[A\n",
      "Downloading data: 24.1MB [00:03, 4.34MB/s]\u001B[A\n",
      "Downloading data: 24.6MB [00:04, 2.22MB/s]\u001B[A\n",
      "Downloading data: 26.3MB [00:04, 4.02MB/s]\u001B[A\n",
      "Downloading data: 27.2MB [00:04, 4.85MB/s]\u001B[A\n",
      "Downloading data: 28.4MB [00:04, 6.22MB/s]\u001B[A\n",
      "Downloading data: 29.4MB [00:04, 6.58MB/s]\u001B[A\n",
      "Downloading data: 30.3MB [00:04, 6.94MB/s]\u001B[A\n",
      "Downloading data: 31.2MB [00:05, 5.12MB/s]\u001B[A\n",
      "Downloading data: 32.3MB [00:05, 6.38MB/s]\u001B[A\n",
      "Downloading data: 33.3MB [00:05, 7.06MB/s]\u001B[A\n",
      "Downloading data: 34.3MB [00:05, 7.24MB/s]\u001B[A\n",
      "Downloading data: 35.5MB [00:05, 8.10MB/s]\u001B[A\n",
      "Downloading data: 36.4MB [00:05, 8.30MB/s]\u001B[A\n",
      "Downloading data: 37.7MB [00:05, 9.08MB/s]\u001B[A\n",
      "Downloading data: 38.7MB [00:06, 9.35MB/s]\u001B[A\n",
      "Downloading data: 39.7MB [00:06, 9.13MB/s]\u001B[A\n",
      "Downloading data: 40.7MB [00:06, 9.27MB/s]\u001B[A\n",
      "Downloading data: 41.6MB [00:06, 9.21MB/s]\u001B[A\n",
      "Downloading data: 42.5MB [00:06, 6.18MB/s]\u001B[A\n",
      "Downloading data: 44.0MB [00:06, 7.90MB/s]\u001B[A\n",
      "Downloading data: 45.1MB [00:06, 8.52MB/s]\u001B[A\n",
      "Downloading data: 46.0MB [00:06, 8.81MB/s]\u001B[A\n",
      "Downloading data: 47.0MB [00:07, 8.32MB/s]\u001B[A\n",
      "Downloading data: 48.0MB [00:07, 8.58MB/s]\u001B[A\n",
      "Downloading data: 49.5MB [00:07, 6.72MB/s]\u001B[A\n",
      "Downloading data files: 100%|██████████| 1/1 [00:13<00:00, 13.32s/it]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]C:\\Users\\Bruno\\Desktop\\JupyterProject\\.venv1\\Lib\\site-packages\\datasets\\download\\streaming_download_manager.py:765: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n",
      "Generating train split: 132373 examples [00:13, 9844.89 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       submission_date                                        reviewer_id  \\\n",
      "0  2018-01-01 00:11:28  d0fb1ca69422530334178f5c8624aa7a99da47907c44de...   \n",
      "1  2018-01-01 00:13:48  014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...   \n",
      "2  2018-01-01 00:26:02  44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...   \n",
      "3  2018-01-01 00:35:54  ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...   \n",
      "4  2018-01-01 01:00:28  7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...   \n",
      "\n",
      "  product_id                                       product_name  \\\n",
      "0  132532965  Notebook Asus Vivobook Max X541NA-GO472T Intel...   \n",
      "1   22562178               Copo Acrílico Com Canudo 500ml Rocie   \n",
      "2  113022329  Panela de Pressão Elétrica Philips Walita Dail...   \n",
      "3  113851581               Betoneira Columbus - Roma Brinquedos   \n",
      "4  131788803  Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...   \n",
      "\n",
      "    product_brand      site_category_lv1       site_category_lv2  \\\n",
      "0            None            Informática                Notebook   \n",
      "1            None  Utilidades Domésticas  Copos, Taças e Canecas   \n",
      "2  philips walita        Eletroportáteis         Panela Elétrica   \n",
      "3     roma jensen             Brinquedos   Veículos de Brinquedo   \n",
      "4              lg      TV e Home Theater                      TV   \n",
      "\n",
      "                       review_title  overall_rating recommend_to_a_friend  \\\n",
      "0                               Bom               4                   Yes   \n",
      "1  Preço imbatível, ótima qualidade               4                   Yes   \n",
      "2      ATENDE TODAS AS EXPECTATIVA.               4                   Yes   \n",
      "3        presente mais que desejado               4                   Yes   \n",
      "4            Sem duvidas, excelente               5                   Yes   \n",
      "\n",
      "                                         review_text  reviewer_birth_year  \\\n",
      "0  Estou contente com a compra entrega rápida o ú...               1958.0   \n",
      "1  Por apenas R$1994.20,eu consegui comprar esse ...               1996.0   \n",
      "2  SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...               1984.0   \n",
      "3  MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...               1985.0   \n",
      "4  A entrega foi no prazo, as americanas estão de...               1994.0   \n",
      "\n",
      "  reviewer_gender reviewer_state  \n",
      "0               F             RJ  \n",
      "1               M             SC  \n",
      "2               M             SP  \n",
      "3               F             SP  \n",
      "4               M             MG  \n",
      "                id                                               text  label  \\\n",
      "199995  es_0715276  Tal y como se describe\\n\\nMando funciona perfe...      4   \n",
      "199996  es_0085190  Funciona perfectamente\\n\\nCompré la batería co...      4   \n",
      "199997  es_0484496  Buena calidad.\\n\\nBuena calidad. Satisfecha co...      4   \n",
      "199998  es_0930141  Recomendado\\n\\nPerfecto para el cumple de mi hijo      4   \n",
      "199999  es_0859809  Preciosas\\n\\nSúper bien! Las brochas son buena...      4   \n",
      "\n",
      "       label_text  \n",
      "199995          4  \n",
      "199996          4  \n",
      "199997          4  \n",
      "199998          4  \n",
      "199999          4  \n",
      "Sucesso! Dataset unificado com 200000 e 132373 registros.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Informações Técnicas e Tamanho\n",
    "Aqui estão os dados atualizados para o seu planejamento de infraestrutura:\n",
    "\n",
    "Tamanho Físico (Disco): Aproximadamente 160 MB para os arquivos compactados (PT + ES).\n",
    "\n",
    "Tamanho em Memória (RAM): Após carregar no Pandas, espere algo em torno de 450 MB a 600 MB. É um tamanho excelente para os limites gratuitos do Google Colab ou máquinas locais.\n",
    "\n",
    "Qualidade: São 400.000 avaliações reais (200k de cada país), todas rotuladas de 1 a 5 estrelas.\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "s9c3bLlqn-g5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Ajuste no Pré-processamento (JSON-ready)\n",
    "Para garantir que o seu modelo aprenda bem os dois idiomas e esteja pronto para o formato JSON da sua API, use este bloco para finalizar a limpeza:\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "G_dTCA5EoQWN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Transformando em binário (Positivo/Negativo)\n",
    "# Removemos as 3 estrelas (neutro) para simplificar a classificação no Hackathon\n",
    "df = df[df['stars'] != 3].copy()\n",
    "df['label'] = df['stars'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# Limpeza rápida\n",
    "df['review_body'] = df['review_body'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "print(\"Exemplo de dado processado:\")\n",
    "print(df[['review_body', 'label', 'language']].head())"
   ],
   "metadata": {
    "id": "GNACEY1ynva_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Código: Treino e Comparação de Performance (PT vs ES)\n",
    "<br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "vkNj-0jdonNY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 1. Carregar Dados de forma estável via Hugging Face\n",
    "print(\"A carregar dados...\")\n",
    "ds_pt = load_dataset(\"amazon_reviews_multi\", \"pt\", split=\"train\")\n",
    "ds_es = load_dataset(\"amazon_reviews_multi\", \"es\", split=\"train\")\n",
    "\n",
    "df = pd.concat([ds_pt.to_pandas(), ds_es.to_pandas()], ignore_index=True)\n",
    "\n",
    "# 2. Pré-processamento\n",
    "df = df[df['stars'] != 3].copy()\n",
    "df['label'] = df['stars'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# 3. Divisão Treino/Teste mantendo a referência do idioma\n",
    "X = df[['review_body', 'language']]\n",
    "y = df['label']\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Treinar o Pipeline\n",
    "# Nota: Passamos apenas a coluna de texto para o fit\n",
    "model_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "print(\"A treinar o modelo bilíngue...\")\n",
    "model_pipeline.fit(X_train_df['review_body'], y_train)\n",
    "\n",
    "# 5. Avaliação Comparativa por Idioma\n",
    "metrics = []\n",
    "\n",
    "for lang in ['pt', 'es']:\n",
    "    # Filtrar o set de teste por idioma\n",
    "    mask = X_test_df['language'] == lang\n",
    "    X_lang = X_test_df[mask]['review_body']\n",
    "    y_lang = y_test[mask]\n",
    "\n",
    "    # Predição\n",
    "    preds = model_pipeline.predict(X_lang)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    acc = accuracy_score(y_lang, preds)\n",
    "    f1 = f1_score(y_lang, preds)\n",
    "\n",
    "    metrics.append({'Idioma': 'Português' if lang == 'pt' else 'Espanhol',\n",
    "                    'Acurácia': acc, 'F1-Score': f1})\n",
    "\n",
    "results_df = pd.DataFrame(metrics)\n",
    "\n",
    "# 6. Visualização para o Pitch\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_plot = results_df.melt(id_vars='Idioma', var_name='Métrica', value_name='Valor')\n",
    "sns.barplot(data=df_plot, x='Idioma', y='Valor', hue='Métrica', palette='viridis')\n",
    "\n",
    "plt.title('Performance do Modelo por Idioma', fontsize=15)\n",
    "plt.ylim(0.8, 1.0) # Zoom para ver as diferenças\n",
    "plt.ylabel('Score (0 a 1)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTabela de Resultados:\")\n",
    "print(results_df)\n",
    "\n",
    "# Guardar o modelo final\n",
    "joblib.dump(model_pipeline, 'modelo_multilingue_final.pkl')"
   ],
   "metadata": {
    "id": "KvdZ_eehovWS"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por que isto é importante para o seu Hackathon?\n",
    "Validação de Viés: Se a acurácia no Espanhol for muito menor que no Português, o júri pode questionar a qualidade dos dados. Este gráfico mostra que o modelo é robusto em ambos.\n",
    "\n",
    "Visualização Profissional: Slides com gráficos de barras bem acabados (usando o seaborn) passam muito mais credibilidade do que apenas números num terminal.\n",
    "\n",
    "F1-Score: Incluí o F1-Score porque ele é mais \"honesto\" que a Acurácia se houver um desequilíbrio entre comentários positivos e negativos.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "Ghdx0bnLo9QJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com a sua base de dados unificada (Português e Espanhol) e o modelo treinado, o passo final é a API. Ela será o \"coração\" do seu projeto no Hackathon, permitindo que qualquer aplicação consuma a inteligência que você criou.\n",
    "\n",
    "Para isso, utilizaremos o FastAPI pela sua velocidade e a biblioteca langdetect para identificar o idioma automaticamente.\n",
    "\n",
    "1. Requisitos do Sistema\n",
    "No ambiente onde a API vai rodar (seu computador ou servidor), instale estas bibliotecas:\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# pip install fastapi uvicorn joblib scikit-learn langdetect\n",
    "```\n",
    "\n",
    "<br>\n",
    "2. O Código da API (main.py)\n",
    "Este script carrega o arquivo modelo_multilingue_final.pkl que geramos no passo anterior e expõe um endpoint de predição."
   ],
   "metadata": {
    "id": "cFRTdez_pmsw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Garante que os resultados da detecção de idioma sejam determinísticos\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# 1. Definição do App\n",
    "app = FastAPI(\n",
    "    title=\"API de Sentimento Multilíngue (PT/ES)\",\n",
    "    description=\"API para classificação de sentimento e detecção de idioma para o Hackathon.\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# 2. Carregar o Modelo (Pipeline com TF-IDF + Logistic Regression)\n",
    "try:\n",
    "    model = joblib.load('modelo_multilingue_final.pkl')\n",
    "    print(\"Modelo carregado com sucesso!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: O arquivo 'modelo_multilingue_final.pkl' não foi encontrado.\")\n",
    "\n",
    "# 3. Modelos de Dados (JSON Schema)\n",
    "class SentimentRequest(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    text: str\n",
    "    sentiment: str\n",
    "    probability: float\n",
    "    language: str\n",
    "    status: str\n",
    "\n",
    "# 4. Rotas\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"message\": \"API Online. Vá para /docs para testar via Swagger.\"}\n",
    "\n",
    "@app.post(\"/predict\", response_model=SentimentResponse)\n",
    "async def predict_sentiment(request: SentimentRequest):\n",
    "    if not request.text.strip():\n",
    "        raise HTTPException(status_code=400, detail=\"O texto fornecido está vazio.\")\n",
    "\n",
    "    try:\n",
    "        # A. Detecção de Idioma\n",
    "        # Identifica se é 'pt', 'es', etc.\n",
    "        lang = detect(request.text)\n",
    "\n",
    "        # B. Predição de Sentimento\n",
    "        # O modelo já processa o texto bruto via TF-IDF (Pipeline)\n",
    "        prediction = model.predict([request.text])[0]\n",
    "        probabilities = model.predict_proba([request.text])[0]\n",
    "\n",
    "        # Mapeamento: 1 -> Positivo, 0 -> Negativo\n",
    "        sentiment_label = \"Positivo\" if prediction == 1 else \"Negativo\"\n",
    "        confidence = float(probabilities.max())\n",
    "\n",
    "        return {\n",
    "            \"text\": request.text,\n",
    "            \"sentiment\": sentiment_label,\n",
    "            \"probability\": round(confidence, 4),\n",
    "            \"language\": lang,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"text\": request.text,\n",
    "            \"sentiment\": \"N/A\",\n",
    "            \"probability\": 0.0,\n",
    "            \"language\": \"unknown\",\n",
    "            \"status\": f\"Error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    # Inicia o servidor na porta 8000\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ],
   "metadata": {
    "id": "4zAETjd-qDMu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Por que esta API é excelente para o seu projeto?\n",
    "Detecção Automática: Ao retornar o campo \"language\": \"es\", você mostra que sua solução é inteligente. Se o usuário mandar \"Me encanta este produto\", a API dirá que o idioma é Espanhol e o sentimento é Positivo.\n",
    "\n",
    "Validação de Dados: O uso do BaseModel (Pydantic) garante que, se alguém tentar enviar algo que não seja texto, a API retornará um erro 422 Unprocessable Entity automaticamente, protegendo seu código.\n",
    "\n",
    "Documentação Viva (Swagger): Ao rodar a API e acessar http://localhost:8000/docs, você terá uma interface visual pronta. Dica de Hackathon: Use essa tela durante a apresentação para mostrar o modelo funcionando em tempo real para os jurados.\n",
    "\n",
    "Como testar no terminal (Curl)\n",
    "Enquanto a API estiver rodando, você ou seu time de Front-end podem testar assim:\n",
    "<br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "jwq6ManbqG5Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "curl -X 'POST' \\\n",
    "  'http://localhost:8000/predict' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \"text\": \"Este serviço é horrível e não funciona.\" }'"
   ],
   "metadata": {
    "id": "_rI7bsfxqPqn"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resultado esperado (JSON):\n",
    "<br><br>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "HLRVanN7qVRY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "{\n",
    "  \"text\": \"Este serviço é horrível e não funciona.\",\n",
    "  \"sentiment\": \"Negativo\",\n",
    "  \"probability\": 0.9854,\n",
    "  \"language\": \"pt\",\n",
    "  \"status\": \"success\"\n",
    "}"
   ],
   "metadata": {
    "id": "LxGx_A8Iqa62"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
